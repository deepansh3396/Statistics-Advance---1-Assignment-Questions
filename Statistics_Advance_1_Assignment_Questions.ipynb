{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#1. Explain the properties of the F-distribution.\n",
        "##The F-distribution is a continuous probability distribution that arises frequently in statistics, particularly in the context of hypothesis testing, analysis of variance (ANOVA), and regression analysis. It is used to compare variances and is often the basis for tests involving ratios of variances between two populations or groups.\n",
        "##Shape of the Distribution >> The F-distribution is skewed to the right, meaning it is positively skewed. It has a longer tail on the right side of its peak. >> As the degrees of freedom for the numerator and denominator increase, the distribution becomes more symmetric and approaches a normal distribution.\n",
        "##Degrees of Freedom >> The F-distribution is defined by two parameters >> Numerator degrees of freedom (df₁): This corresponds to the degrees of freedom associated with the variance estimate in the numerator of the F-ratio. >>Denominator degrees of freedom (df₂): This corresponds to the degrees of freedom associated with the variance estimate in the denominator of the F-ratio.\n",
        "##The exact shape of the distribution depends on these two degrees of freedom, and different combinations lead to different distributions.\n",
        "##Range of Values >> The F-distribution takes values in the range [0, ∞). It cannot take negative values, as variances and squared terms (such as those used in the numerator and denominator of the F-ratio) are always non-negative.\n",
        "##Mean >> The mean of an F-distribution depends on the degrees of freedom.\n",
        "##Variance >> The variance of an F-distribution is also dependent on the degrees of freedom.\n",
        "##Skewness >> The F-distribution is positively skewed, and the skewness decreases as the degrees of freedom increase. The distribution becomes approximately symmetric when both df₁ and df₂ are large.\n",
        "##Mode >> The mode (the value at which the distribution reaches its maximum) of the F-distribution is located at:\n",
        "##Tail Behavior >> The F-distribution has a long right tail, which indicates that extreme values (far from the mean) are possible, especially when df₁ and df₂ are small. >> The tail behavior is often used in hypothesis testing for significance, where the critical value of the F-distribution determines the threshold beyond which a result is considered statistically significant.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sgDKpdVH2fvB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?\n",
        "##The F-distribution is primarily used in statistical tests that compare variances and in tests related to the analysis of variance (ANOVA). Here are the main contexts in which the F-distribution is used\n",
        "##Analysis of Variance (ANOVA) >> ANOVA is used to compare the means of two or more groups to see if there is a significant difference between them. >>Use of F-distribution: In ANOVA, the F-statistic is used to test the null hypothesis that all group means are equal. The F-statistic is the ratio of two variances >> Between-group variance (variance due to the differences in the group means) >> Within-group variance (variance within each group) >> Why F-distribution?: The F-distribution is used because it models the ratio of two variances, each estimated from different samples (groups). The distribution is right-skewed and is used to assess whether the variance between groups is significantly larger than the variance within groups.\n",
        "##Testing for Equality of Variances (F-test) >>  The F-test is used to compare the variances of two populations to see if they are equal. >> Use of F-distribution: When comparing the variances of two independent samples, the F-statistic is calculated as the ratio of the two sample variances. Under the null hypothesis, the ratio follows an F-distribution. >> Why F-distribution?: The F-distribution is appropriate because it represents the ratio of two independent estimates of variance, assuming the data in each group is normally distributed.\n",
        "##Regression Analysis >>  In multiple regression, the F-test is used to determine whether the model as a whole fits the data better than a model with no predictors. >> Use of F-distribution: The F-statistic is computed to test the significance of the regression model. It compares the explained variance (the variance accounted for by the predictors) to the unexplained variance (the residual variance). >> Why F-distribution?: The F-distribution is used because the statistic involves comparing the variance explained by the regression model to the unexplained variance, similar to how variances are compared in ANOVA.\n",
        "##Ratio of variances: The F-statistic is inherently a ratio of two independent chi-squared variables (scaled by their respective degrees of freedom). This ratio follows an F-distribution.\n",
        "##Non-negative values: Since variances cannot be negative, the F-distribution is constrained to positive values, which is appropriate for tests involving variance ratios.\n",
        "##Shape: The F-distribution is right-skewed, which fits the nature of variance ratios (they are typically not symmetrically distributed, especially when sample sizes are small).\n",
        "\n"
      ],
      "metadata": {
        "id": "OeP5SmcG4Tqg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. What are the key assumptions required for conducting an F-test to compare the variances of two populations?\n",
        "##The F-test is commonly used to compare the variances of two populations. For the F-test to be valid, several key assumptions must be met:\n",
        "##Independence >> The two samples should be independent of each other. This means that the data points in one sample should not influence or be related to the data points in the other sample.\n",
        "##Normality >> The populations from which the samples are drawn should be normally distributed. This assumption is crucial because the F-test relies on the ratio of the sample variances, and this ratio follows an F-distribution only if the underlying populations are normally distributed.\n",
        "##Random Sampling >> The samples should be randomly selected from their respective populations. Random sampling ensures that the sample data is representative of the population, and it helps to avoid bias.\n",
        "##Homogeneity of Variance (Optional, for some tests) >> The F-test assumes that the populations being compared have the same variance. However, this is typically the null hypothesis in the F-test (i.e., testing whether the two variances are equal). If the null hypothesis is rejected, it indicates that the variances are significantly different.\n",
        "##Ratio of variances >> The F-statistic is calculated as the ratio of the sample variances from the two populations. For the F-distribution to be valid, it is important that the larger variance is placed in the numerator (i.e., the larger variance is divided by the smaller one). This ensures that the F-statistic follows a proper distribution."
      ],
      "metadata": {
        "id": "QOKVSqKo6QDB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4. What is the purpose of ANOVA, and how does it differ from a t-test?\n",
        "##ANOVA (Analysis of Variance) and the t-test are both statistical methods used to assess whether there are significant differences between groups, but they are used in different contexts and are based on different underlying assumptions.\n",
        "##Purpose of ANOVA >> ANOVA is used to compare the means of three or more groups to determine if at least one group is significantly different from the others. It works by analyzing the variance within groups and between groups. The idea is that if the variance between groups is much greater than the variance within groups, then there is evidence to suggest that the group means are not all equal.\n",
        "##One-way ANOVA >> Compares the means of three or more independent groups based on one factor (e.g., testing the effect of three different diets on weight loss).\n",
        "##Two-way ANOVA >> Compares means based on two factors, allowing for the study of interaction effects between them (e.g., studying both diet and exercise on weight loss).\n",
        "\n",
        "##Purpose of the t-test >> The t-test is used to compare the means of two groups to determine if they are significantly different from each other. It comes in three forms:\n",
        "##Independent samples t-test >> Compares the means of two independent groups (e.g., comparing the mean scores of males and females on a test).\n",
        "##Paired samples t-test >> Compares the means of the same group at two different times or under two different conditions (e.g., comparing pre- and post-test scores).\n",
        "##One-sample t-test >> Compares the mean of a single sample to a known value or population mean."
      ],
      "metadata": {
        "id": "VspulauN7rTZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups.\n",
        "##When comparing more than two groups, you would use a one-way ANOVA (Analysis of Variance) instead of multiple t-tests for several important reasons:\n",
        "##Control for Type I Error Rate >> Multiple t-tests: If you conduct separate t-tests for each pair of groups, the probability of committing a Type I error (false positive) increases as the number of comparisons increases. This is because each t-test has its own chance of incorrectly rejecting the null hypothesis (e.g., concluding that there is a difference between two groups when there is not). As you add more t-tests, the overall likelihood of making at least one Type I error grows, which is called the inflation of the family-wise error rate (FWER). >> One-way ANOVA: A one-way ANOVA tests all groups simultaneously and controls the Type I error rate. Instead of comparing groups pair by pair, ANOVA assesses whether there is any significant difference among all groups at once, reducing the risk of inflated error rates.\n",
        "##Statistical Efficiency >> Multiple t-tests: Each t-test compares just two groups at a time, and you need to conduct a large number of comparisons. This is less efficient and can lead to unnecessary redundancy in testing. >> One-way ANOVA: ANOVA is a more efficient method for comparing multiple groups simultaneously. It provides a single test that evaluates whether there are any overall differences between the means of the groups, which is computationally simpler and more elegant.\n",
        "##Interpretation of Results >> Multiple t-tests: After performing multiple t-tests, you would have to report and interpret the p-values for each pair of groups. The results can be overwhelming, and it becomes more difficult to determine the overall pattern of relationships between the groups. >> One-way ANOVA: The result of a one-way ANOVA provides a single p-value that answers the question: \"Is there a significant difference between at least two of the group means?\" If the ANOVA is significant, you can then proceed with post-hoc tests (like Tukey’s HSD) to identify exactly which groups differ from each other, but the initial test allows you to focus on the big picture first.\n",
        "##Assumptions >> Both t-tests and ANOVA assume that the data is approximately normally distributed within each group, and that the groups have equal variances (homogeneity of variances). However, ANOVA is generally better equipped to handle the comparisons across multiple groups simultaneously, while the multiple t-test approach may be more prone to violating assumptions when multiple tests are involved."
      ],
      "metadata": {
        "id": "DQIBeRYG8hbp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance. How does this partitioning contribute to the calculation of the F-statistic?\n",
        "##In Analysis of Variance (ANOVA), variance is partitioned into between-group variance and within-group variance to evaluate whether there are statistically significant differences between the means of different groups or treatments. Here’s how the partitioning works and how it contributes to the F-statistic calculation:\n",
        "##Total Variance >> The total variance refers to the overall variation in the data, which is measured by the total sum of squares (SS total).This total variance reflects the variation in all observations, regardless of which group they belong to.\n",
        "##Between-group Variance (SS between) >> This is the variance due to the differences between the means of the groups. The between-group sum of squares (SS between). between measures how much the group means vary from the overall mean of all data points. It essentially captures the effect of the treatment or grouping variable.The formula for between-group variance involves calculating the squared deviations of each group's mean from the overall mean, weighted by the number of observations in each group.The between-group variance indicates how much of the total variation can be explained by the differences in group means. If the between-group variance is large compared to the within-group variance, this suggests that the groups differ significantly.\n",
        "##Within-group Variance (SS within) >> This is the variance within each group. The within-group sum of squares (SS within). (SS within) measures the variation of individual observations within each group, reflecting the inherent variability due to individual differences or experimental error.\n",
        "##The F-statistic >> The F-statistic is the ratio of the between-group variance to the within-group variance."
      ],
      "metadata": {
        "id": "kkWW9rnESCjj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?\n",
        "##The classical (frequentist) approach and the Bayesian approach to ANOVA differ in several important ways, particularly in how they handle uncertainty, parameter estimation, and hypothesis testing. Below is a comparison of these two perspectives:\n",
        "##Handling Uncertainty >>\n",
        "#Frequentist Approach >> In the classical ANOVA framework, uncertainty is modeled through the sampling distribution of the estimator, often using a fixed model with unknown parameters. The variance and the error term are considered to be fixed but unknown. >> The focus is on the probability of the observed data, assuming a fixed set of parameters. The uncertainty about parameters is expressed through their sampling distribution under repeated sampling.\n",
        "#Bayesian Approach >>\n",
        "#The Bayesian approach treats uncertainty about parameters as intrinsic to the model. Parameters are considered to be random variables with prior distributions that express beliefs or knowledge before observing data. >> The Bayesian model updates this prior knowledge with observed data to form a posterior distribution. Thus, the uncertainty is expressed through the entire distribution of the parameters, not just through a point estimate or interval.\n",
        "##Parameter Estimation\n",
        "#Frequentist Approach >> Parameter estimation is typically done through point estimates, such as the sample mean or maximum likelihood estimators. The estimates are fixed values that do not change based on prior information or subjective belief. >> The frequentist approach often uses confidence intervals to quantify uncertainty about parameters. These intervals are constructed so that, in the long run, a certain percentage of them would contain the true parameter value if the experiment were repeated many times.\n",
        "#Bayesian Approach >> In contrast, the Bayesian approach estimates parameters through the posterior distribution, which represents a combination of prior beliefs and the information provided by the data. >> The posterior mean (or median) is often used as a point estimate, but more importantly, the entire posterior distribution is available, allowing for the calculation of credible intervals (the Bayesian equivalent of confidence intervals) that represent the range of plausible parameter values.\n",
        "##Hypothesis Testing >>\n",
        "#Frequentist Approach >> In classical ANOVA, the hypothesis testing framework is built around null hypothesis significance testing (NHST). The null hypothesis typically states that there is no effect (e.g., no difference between group means). A p-value is computed, which is the probability of obtaining the observed data (or more extreme data) under the null hypothesis. >> If the p-value is less than a predefined significance level (e.g., 0.05), the null hypothesis is rejected. The test is designed around controlling the Type I error rate, the probability of wrongly rejecting a true null hypothesis.\n",
        "#Bayesian Approach >> Bayesian hypothesis testing does not rely on a p-value but rather on the posterior probability of a hypothesis. The Bayes factor (the ratio of the posterior odds of two competing hypotheses) can be used to compare models. >> Rather than testing against a fixed null hypothesis, the Bayesian approach evaluates the relative support for different hypotheses or models, providing a continuous measure of evidence in favor of one model over another. This is done through comparing posterior probabilities or Bayes factors.\n",
        "##Interpretation of Results >>\n",
        "#Frequentist Approach >>The frequentist interpretation focuses on the long-run frequency of events under repeated sampling. For instance, a confidence interval is interpreted as the range within which the true parameter would fall in 95% of repeated experiments. >> Hypothesis tests provide a binary outcome: reject or fail to reject the null hypothesis, based on the p-value.\n",
        "#Bayesian Approach >> The Bayesian interpretation is probabilistic and provides a direct probability of hypotheses or parameter values. For example, a 95% credible interval in the Bayesian framework is interpreted as the range within which the true parameter value lies with 95% probability, given the observed data and prior information. >> Instead of p-values, results are often interpreted in terms of how strongly the data support one hypothesis over another, often using the posterior distribution to make probabilistic statements.\n",
        "##Model Comparison >>\n",
        "#Frequentist Approach >>In frequentist ANOVA, model comparison is generally performed using F-tests to compare variances between groups. These tests are based on the ratio of between-group variance to within-group variance and require assumptions about the distribution of the data (e.g., normality and homogeneity of variance). >> Multiple comparisons are often corrected for using methods like Tukey’s HSD to control Type I error when testing multiple hypotheses.\n",
        "#Bayesian Approach >> In Bayesian ANOVA, model comparison can be done using Bayes factors, which directly compare the likelihood of the data under competing models. Bayesian methods allow for more flexible model comparisons, especially when the models involve different prior assumptions or when the data are not well-behaved (e.g., non-normal or heteroscedastic). >> Model comparison in a Bayesian framework is more nuanced and can integrate information across all models, rather than relying on a single test statistic like the F-test.\n",
        "## Assumptions >>\n",
        "#Frequentist Approach >> The frequentist ANOVA relies heavily on specific assumptions, such as normality of the residuals and homogeneity of variance (equal variances across groups). Violations of these assumptions can lead to biased results or invalid inferences.\n",
        "#Bayesian Approach >> The Bayesian approach is often more flexible in accommodating violations of these assumptions. For example, non-normal or heteroscedastic data can often be modeled more appropriately by specifying a suitable prior or likelihood function. However, the choice of prior still plays a critical role in the analysis.\n"
      ],
      "metadata": {
        "id": "dtVqbJ1UT-1v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Question: You have two sets of data representing the incomes of two different professions Profession A: [48, 52, 55, 60, 62 Profession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions' incomes are equal. What are your conclusions based on the F-test? Task: Use Python to calculate the F-statistic and p-value for the given data. Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison.\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Data for Profession A and Profession B\n",
        "profession_a = [48, 52, 55, 60, 62]\n",
        "profession_b = [45, 50, 55, 52, 47]\n",
        "\n",
        "# Calculate the variances of both sets\n",
        "var_a = np.var(profession_a, ddof=1)  # Sample variance (ddof=1 for unbiased estimate)\n",
        "var_b = np.var(profession_b, ddof=1)\n",
        "\n",
        "# Calculate the F-statistic\n",
        "F_statistic = var_a / var_b if var_a > var_b else var_b / var_a\n",
        "\n",
        "# Perform the F-test\n",
        "df1 = len(profession_a) - 1  # Degrees of freedom for profession A\n",
        "df2 = len(profession_b) - 1  # Degrees of freedom for profession B\n",
        "\n",
        "# p-value for the F-test\n",
        "p_value = stats.f.sf(F_statistic, df1, df2)\n",
        "\n",
        "# Output the results\n",
        "print(f\"Variance of Profession A: {var_a}\")\n",
        "print(f\"Variance of Profession B: {var_b}\")\n",
        "print(f\"F-statistic: {F_statistic}\")\n",
        "print(f\"p-value: {p_value}\")\n",
        "\n",
        "# Conclusion\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The variances are significantly different.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The variances are not significantly different.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S89IWAiVWyAU",
        "outputId": "3d6e43cd-4537-4b27-861a-275f1cf91b35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance of Profession A: 32.8\n",
            "Variance of Profession B: 15.7\n",
            "F-statistic: 2.089171974522293\n",
            "p-value: 0.24652429950266966\n",
            "Fail to reject the null hypothesis: The variances are not significantly different.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in average heights between three different regions with the following data Region A: [160, 162, 165, 158, 164 Region B: [172, 175, 170, 168, 174 Region C: [180, 182, 179, 185, 183 Task: Write Python code to perform the one-way ANOVA and interpret the results Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value.\n",
        "\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Data for each region\n",
        "region_A = [160, 162, 165, 158, 164]\n",
        "region_B = [172, 175, 170, 168, 174]\n",
        "region_C = [180, 182, 179, 185, 183]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "f_statistic, p_value = stats.f_oneway(region_A, region_B, region_C)\n",
        "\n",
        "# Output the results\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05  # Common significance level\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between at least one pair of regions.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference between the regions.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzS4gVjYXQBp",
        "outputId": "22c9fedf-af8c-4762-fdad-1a6b4d56e768"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-statistic: 67.87330316742101\n",
            "P-value: 2.870664187937026e-07\n",
            "Reject the null hypothesis: There is a significant difference between at least one pair of regions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WrofPYFxXtxu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}